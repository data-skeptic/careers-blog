In April 2020, I decided to get serious with self-learning Data Science. Like everyone else, I went on a Google search spree. I searched for topics such as how to get started with data science, the best tools every Data Scientist should master, should I learn Python or R?, is Tensorflow better than Pytorch? you name it. I was inundated with a lot of information and was almost overwhelmed. Slowly but surely, I began to filter through the noise and learnt critical tools that progressed my data science career.

In this article, I will share 5 key technologies that changed my career in data science and I think every data science enthusiast should master them. Let’s dive in.

## 1. Python
    

Python is a popular dynamically-typed programming language used for many applications. Python can be used for data science, web development, cyber security, software testing and so on. As mentioned earlier, I was initially torn between learning Python or R. But I finally learned Python and it turned out to be a good decision. I had taken two programming courses in Java in my undergraduate program, so learning Python was relatively easier. Asides from Python having a gradual learning curve, its diversified applications are an added advantage for data scientists.

For instance, a data scientist may need to scrape data from the web. Python has powerful libraries such as BeautifulSoup and Selenium that allow you to perform web scraping with ease. In addition, if you need to deploy your machine learning models to production, there are Python frameworks to the rescue. With the help of Flask, Django or Streamlit, you can build a full-fledged web application with just a little additional knowledge of HTML and CSS. 

So you see, the singular act of learning Python opens you up to many possibilities. It is practically sufficient to get you going as a data scientist. Whether you want to web scrape, analyze data, build machine learning models or deploy the model, Python could be the one-size-fit-all language for all these processes.

## 2. Pandas, Numpy, Matplotlib and scikit learn
    

Data wrangling, exploratory data analysis and machine learning model building are critical steps in the data science life cycle. In my quest to perform these tasks, I learned how to use Numpy, Pandas, Matplotlib and Scikit learn. While there are many other tools for data wrangling and machine learning, these four proved to be sufficient and indeed powerful.

With numpy and pandas, you can load data from different sources, clean the data, analyze the data, and perform many feature engineering operations. Matplotlib allows you to build strong visualizations and plots while scikit-learn is used for utilizing machine learning algorithms. I used the book by Jake VanderPlas - Python Data Science Handbook: Essential Tools for Working with Data - to learn how to use these tools. I also applied my learnings in building some machine learning projects with tangible results.

Today, Numpy and Pandas are still one of the most used tools for data analysis. As a budding data scientist, you cannot go wrong learning how to use them.

## 3. Keras
    

Scikit learn is a broad tool used for exploiting machine learning algorithms. However, building deep learning models with scikit learning can be a struggle. After completing Jake’s book, I realized I needed to learn deep learning which was not covered in the book.

Deep learning is particularly useful, if you wish to work with unstructured data such as images, texts or videos. For example, it is not suitable to use a traditional machine learning algorithm for an image recognition problem or a language translation. This is because machine learning algorithms cannot handle the level of complex feature engineering that a deep learning model automatically does. Deep learning creates multiple representation spaces that jointly learn the features in the input data and self-corrects.

Having discovered that I needed to learn a deep learning tool, I had the option of Tensorflow, Keras or Pytorch. I chose Keras because it was user friendly, easy to use, and yet powerful for building custom neural network architectures. 

Keras is a high-level API built on top of Tensorflow to build deep learning models. As of 2021, Keras boasts of over 1 million users which include students, researchers and data scientists at both startups and large corporations. It is said that YouTube built its recommendation model using Keras. Keras is also widely used in Netflix, Yelp, Uber, Wells Fargo, etc. In all, Keras helped me grasp and apply the many fancy concepts in deep learning. It was a game changer.

## 4. Postman
    

Postman is a powerful no-code API platform for developers to interact with other APIs. You can easily build and use APIs using Postman’s simple GUI platform. I, for one, think the importance of learning to use APIs for a data scientist is not preached enough. APIs allow you to exchange data easily with other applications. As a data scientist, if you want to scrape data from platforms such as Twitter or YouTube, you would have to use their APIs. Many other platforms have APIs used by developers to formally exchange data. Thus, you would be short changing yourself by not learning how to use APIs.

But different APIs can be built differently, and when the client application does not have proper documentation, you may get stuck. With Postman, you can interface with any API without writing a single line of code. What’s more? You can also get the code for your request in your preferred programming language. 

Postman has helped me a couple of times where I had issues with APIs. Rather than spending hours trying to find the cause, I simply used Postman to perform the task and generate the code in Python. If you have not been using Postman for your API requests, you should definitely consider trying it out.

## 5. GitHub
    

GitHub is a platform that allows developers to store their code and collaborate with other developers seamlessly. What makes GitHub even more special is its version control system. You can easily manage codes and track changes on the platform. This is why GitHub is the most popular git platform and is widely used by many open-sourced projects.

As a data scientist, GitHub helped me collaborate with clients and make requested edits dynamically. GitHub now offers web hosting services for free - a feature data science newbies can take advantage of to build their portfolio websites.

## Wrapping up

There are a plethora of tools for data science out there. However, I have found these five to be super useful in my data science career and believe they have also been useful for millions of others. You too should consider learning them to kickstart your data science career.
